{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from MC import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Blocking analysis\n",
    "\n",
    "In this task, you will study the correlation present in the Monte Carlo simulations\n",
    "from task 1.\n",
    "As you saw in the last exercise, block averaging can be used to obtain more\n",
    "reliable error estimates when sampling is correlated, like in Metropolis sampling.\n",
    "\n",
    "Continuing with the same system of `200` particles at Lennard-Jones temperature\n",
    "and pressure of `T=2.0` and `ρ=0.5` (remember the equlibration!), plot the\n",
    "evolution of block-averaged errors of the energy and pressure w.r.t. the blocking\n",
    "iteration. Increase the number of transforms until the formation of a plateau\n",
    "can be observed. At the onset of the plateau, the block size (how much of the\n",
    "original data that has been reduced to one point) becomes longer than the\n",
    "correlation length. Note that the sampling frequency `fsamp` in the Monte Carlo\n",
    "simulation will affect the interpretation of the blocking analysis!\n",
    "\n",
    "Compare the magnitude of errors computed with and without block-averaging, and\n",
    "compare the correlation length with the number of equilibration steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_transform(x: np.ndarray) -> np.ndarray:\n",
    "    # Drop the last data point if the number of points is odd\n",
    "    n = 2 * (x.shape[0] // 2)\n",
    "    # Average adjacent values\n",
    "    return (x[:n:2] + x[1:n:2]) / 2\n",
    "\n",
    "def blocking_analysis(x: np.ndarray, n_transformations: int):\n",
    "    if 2**n_transformations > data.shape[0]:\n",
    "        raise Exception(\n",
    "            f'Data allows for a maximum of {int(np.log(x.shape[0]) / np.log(2))} transformations.'\n",
    "        )\n",
    "\n",
    "    # Number of samples: N(M=0)\n",
    "    N_0 = x.shape[0]\n",
    "    # Variance: \\sigma_A^2(M=0) = 1/N(M=0) * SUM[ (xi - mean(x))^2 ]\n",
    "    var_0 = np.var(x)\n",
    "\n",
    "    result = np.zeros((n_transformations + 1, 5))\n",
    "\n",
    "    x_M = x.copy()\n",
    "    for M in range(0, n_transformations + 1):\n",
    "        N_M = x_M.shape[0]\n",
    "        var_M = np.var(x_M)\n",
    "\n",
    "        # Blocked correlation time \\tau(M) = var_M 2**M / var_0 | Eq (26)\n",
    "        correlation_time = var_M * 2**M / var_0\n",
    "        # Standard error of the blocked correlation time = sqrt(2/N(M)) * \\tau(M) | Eq (36)\n",
    "        stddev_correlation_time = np.sqrt(2 / N_M) * correlation_time\n",
    "\n",
    "        # Blocked error of the sum \\sigma_I(M) = sqrt( var(M) 2**M / N_0 ) | Eq (27)\n",
    "        stat_err = np.sqrt(var_M * 2**M / N_0)\n",
    "        # Standard error of the blocked error of the sum = 1 / sqrt(2 N(M)) \\sigma_I(M) | Eq (38)\n",
    "        stddev_stat_err = 1 / np.sqrt(2 * N_M) * stat_err\n",
    "\n",
    "        result[M,:] = [M, correlation_time, stddev_correlation_time, stat_err, stddev_stat_err]\n",
    "\n",
    "        # Average neighboring elements\n",
    "        x_M = block_transform(x_M)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "# MC parameters (used to define file to load)\n",
    "rho = 0.5\n",
    "temp = 2.0\n",
    "quantity = 'pressure'  # 'pressure' or 'energy'\n",
    "# Number of blocking transformations\n",
    "# (< log_2(N) where N is the number of data points)\n",
    "n_transformations = 4\n",
    "\n",
    "## Load MC data\n",
    "filename = f'sc_{quantity}_rho={rho:0.4f}_T={temp:0.4f}.dat'\n",
    "data = np.loadtxt(filename)\n",
    "\n",
    "## Blocking analysis\n",
    "blocking_res_dict = {}\n",
    "for n_data in [data.shape[0]]:\n",
    "    blocking_res_dict[n_data] = blocking_analysis(data[:n_data], n_transformations)\n",
    "\n",
    "## Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,4))\n",
    "for (n_data, blocking_res) in blocking_res_dict.items():\n",
    "    axes[0].errorbar(blocking_res[:,0], blocking_res[:,1], marker='.',\n",
    "                    yerr=blocking_res[:,2], capsize=3, label=f'N={n_data}')\n",
    "    axes[1].errorbar(blocking_res[:,0], blocking_res[:,3], marker='.',\n",
    "                 yerr=blocking_res[:,4], capsize=3, label=f'N={n_data}')\n",
    "\n",
    "axes[0].set_ylabel(r'$\\tau(M)$')\n",
    "axes[0].set_xlabel(r'$M$')\n",
    "axes[0].set_xticks(blocking_res[::2,0])\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_ylabel(r'$\\sigma_I(M)$')\n",
    "axes[1].set_xlabel(r'$M$')\n",
    "axes[1].set_xticks(blocking_res[::2,0])\n",
    "axes[1].legend()\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phys-403",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
